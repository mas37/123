## PANNA data preparation tutorial

In the first tutorial, you learned how to use PANNA for training and evaluation with the preprepared data.
In this tutorial we will walk through the steps necessary to 
convert the data that you have from your simulations into 
a format suitable for PANNA training and evaluation steps.

### Introduction

We will convert the output of your simulations into input files for PANNA 
so that they can be used by train.py and evaluate.py scripts.
This procedure is composed of 3 steps:

* Extract the relevant information from your simulation output 
(eg. atomic positions, energy, forces) and write it in `json` format compatible with PANNA.
* Calculate the local descriptors (a.k.a. g-vectors, symmetry functions) 
for each atom with specified parameters and store them in a binary file.
* Pack multiple descriptor files in TensorFlow record format compatible with PANNA.

---

### From simulation output to extracted information in json file

Your simulation results may be stored in QE data_xml files 
or you might be using one of the popular datasets such as ANI-1.
First step is to extract the relevant information into a json file and how to do it strictly depends on the code you use to generate the data. 
Here we will walk through the case of Quantum ESPRESSO and will summarize what to do in the case of ANI-1. 
Should you desire to generate new files from your own simulations with another code, 
here are the fields required to be in your json file:

* `unit_of_length` -- The spatial unit used in the json: can be either `bohr` or `angstrom`. Applies to lattice vectors and atomic positions (in the case of cartesian coordinates).
* `atomic_coordinates` (or `atomic_positions_unit`) -- Can be either `cartesian`, for absolute positions, or `crystal` for positions in units of the lattice vectors.
* `lattice_vectors` -- A list of three lists, where each list is a lattice vector with 3 elements, i.e. [[a1x, a1y, a1z],[a2x, ...],[]] . If missing or set to `[[0, 0, 0], [0, 0, 0], [0, 0, 0]]`, the simulation is considered aperiodic in all directions.
* `atoms` -- A list of lists containing one element per atom in the simulation
Each entry should contain (in this order):
    * A number label for the atom
    * A string identifying the species of the atom
    * A vector containing the coordinates of the atom, in cartesian or crystal coordinates.
Example json entry: "atoms" : [[1,"C",[0.0, 0.0, 0.0]],[2,"C",[0.25, 0.25, 0.25]]]
* `energy` -- A list with 2 entries: the calculated energy of the simulation and the unit of energy such as eV. Example: "energy": [-13.6, "Ry"].

#### Converting QE file to PANNA json

For this purpose we use the tool qexml_parser.py in the `panna/tools` directory:
```
python ../../panna/tools/qexml_parser.py -i path/to/directory/that/holds/qe/outdir -o path/to/write/the/panna/jsons
```
This tool looks inside the specified input directory and finds all <prefix>.xml files that are stored in the same level of .save directories.
Then it creates a json file with the same name of the xml at the position of the output directory.
The extension of the generated json is ".example".
If you want the names of json files to be unique, and do not care them to be related to QE prefix, 
you can use the hashing function as an option:
```
python ../../panna/tools/qe_parser.py --addhash -i path/to/directory/that/holds/qe/outdir -o path/to/write/the/panna/jsons
```
For the sake of tutorial we prepared 10 qe data xml files in directory `tutorial_data/qe_xml` that are generated by QE. 
We will convert these to PANNA example jsons and store them in a directory called `tutorial_data/qe_sims`
```
cd doc/tutorial
python ../../panna/tools/qe_parser.py -i tutorial_data/qe_xmls -o tutorial_data/qe_sims
ls 
```
Last command should list all the 10 example jsons. Visualize one to see the fields described above.
The file format is not intended to be human readable but in this simple case you can.
Note that we  have added two fields in the jsons that are not mandatory (ie PANNA does not use them) but 
you might find handy: `source` holds the location of the source xml file and `key` holds the prefix used in the qe calculation.
Once these json files are ready, you can proceed with the next step of converting them to local descriptors. 

#### Converting ANI set to PANNA json

Instead of QE data, you can use ANI-1 set that is distributed in the following address in hdf5 format: 
```
https://github.com/isayev/ANI1_dataset
```

Once you have extracted a `.h5` file, you can convert all the simulations it contains to PANNA `json` format by using the tool `ani_parser.py`.
This tool requires some code distributed with the dataset in the `pyanitools.py` file, which is assumed to be in the same folder for import purposes.
The code can then be run as
```
python3 ani_parser.py -in ani_gdb_XX.h5 -out out_folder
```
where `ani_gdb_XX.h5` is the file to be extracted and `out_folder` the destination.
This tool will create a folder for each molecule type and inside it one `.example` file for each configuration, with a uniquely generated hash name.

---

### From example json to input descriptor files

We now assume that you followed the previous step and 
10 example json files have been created and are stored in one folder 
called `simulations`.

We will now convert the information here to a representation that can be understood by the network,
which in general can be thought of any input descriptor, but in the case of atomistic simulations this is often
symmetry functions such as Behler-Parinello G vectors.
The tool to use for this purpose is `gvect_calculator.py`.
It needs an input file defining the necessary parameters and it will generate G vectors and write them to files in binary format.
You can see the input we will use in this tutorial here `input_files/gvect_sample.ini`.
and below is the explanation of its content:
**IMPORTANT NOTE:** Internal units of PANNA are eV and Angstrom. Therefore all the information given to code
will be converted to these units. For example, the json files might use angstroms and eV but the binary G-vector files will
be stored in Ry and au.
##### [IO_INFORMATION]

* `input_json_dir` -- The directory containing the example `json` files (relative to the directory you run the program from).
* `output_gvect_dir` -- The directory to store the output binary gvector files.
* `log_dir` -- The directory where to create the log files for the process.

##### [SYMMETRY_FUNCTION]

* `type` -- The desired flavour or descriptor function. For now the supported types are 
    * `BP` -- Behler-Parrinello type descriptors [1]
    * `mBP` -- Modified Behler-Parrinello type descriptors [2].
    (Note that we take the angular centers as Theta_i = π (i+0.5)/Theta_N, i=[0,..,Theta_N-1])

* `species` -- A comma separated list of species to be found in the simulation files. The order given here is important because the it will be kept throughout the training procedure. Also, the symbol used here needs to match exactly the strings in the `json` files.

* `include_derivatives` -- Boolean. If True, derivative of the descriptor with respect to atomic positions of all atoms is also stored. This is necessary to run force prediction calculations. 
##### [PARALLELIZATION]

* `number_of_process` -- Number or processes to spawn in parallel to compute the gvectors.

##### [GVECT_PARAMETERS]
The parameters entering in the descriptor functions. 
Note that their meaning is consistent with the kind of symmetry function type chosen earlier. 
For example, `RsN_ang` is only parsed for mBP type and not for the original BP functions.
You can use the tool `gvect_param_check.py` in `panna/tools/` to plot how the symmetry function gaussians 
look like as a function of interatomic distances and angles, and tune the parameters below 
according to your needs. 

* `gvect_parameters_unit` -- Unit of length that will be used to interpret the descriptor parameters below. Default is `angstrom`.
(Note that the the g-vectors will be stored in angstroms independently of the user parameter units.)
* `Rc_rad` -- Radial cutoff
* `Rs0_rad` -- Zero bias of radial centers
* `RsN_rad` -- Number or radial functions
* `Rsst_rad` -- Interval between radial centers, if not present will be calculated as ( Rc_rad - Rs0_rad ) / RsN_rad
* `eta_rad` -- Value of η for the radial function (single value in case of mBP descriptor, comma separated list in the case of BP)
* `Rc_ang` -- Radial cutoff for the angular function
* `Rs0_ang` -- [*mBP only*] Zero bias of radial centers for the angular function
* `RsN_ang` -- [*mBP only*] Number or radial centers for the angular function
* `Rsst_ang` --[*mBP only*] Step for the radial centers in the angular funtion, if not present will be calculated as ( Rc_ang - Rs0_ang ) / RsN_ang
* `ThetasN` -- [*mBP only*] Number of angular bins in the angular function
* `eta_ang` -- Value of η for the angular function (single value in case of mBP descriptor, comma separated list in the case of BP)
* `zeta` -- Value of ζ for the angular function (single value in case of mBP descriptor, comma separated list in the case of BP)

##### [PBC]
* `pbc` -- [*optional*] boolean array determining whether boundary conditions are periodic in three dimensions. If not present boundary conditions will be inferred from the input files.

To compute the gvector binaries, run the code `gvect_calculator.py` passing the input file as below:

```
python3 ../../panna/gvect_calculator.py --config input_files/gvect_sample.ini
```

This will create a binary file containing the descriptors for each example file, in our case in the `gvectors` folder. 
It will also create a log file with summary information, and a file called `gvect_already_computed.dat` 
containing the names of the files already processed. 
This way, in case you add new example jsons to your jsons directory, 
you can run this tool again and it will process only the news ones. 
This is also helpful in case the job is interrupted and you want to restart the process.

---

### Converting binary input descriptors to tfrecord files

Once the binary files with the gvectors have been created, we package them for a very efficient read in process. 
We package them in a format called TensorFlow Record (tfr), which allows the underlying TensorFlow engine to rapidly load a lot of data during training. This comes very handy with mini batch training on large amounts of data.
To convert the binary gvectors to tfr's, we run the code `tfr_packer.py` with an appropriate input file.

As an example, we provide a working input file in `input_files/tfr_sample.ini`.
Here we describe the required sections and keywords:

##### [IO_INFORMATION]

* `input_dir` -- The directory containing the binary gvector files (relative to the directory you run the program from).
* `output_dir` -- The directory where the tfr files will be created.
* `prefix` -- An optional prefix to add at the beginning of the output files.

##### [CONTENT_INFORMATION]
* `elements_per_file` -- How many simulations to store in the same input file, can be kept smaller if we want to split our training/evaluation sets in multiple files of manageable size.
* `n_species` -- Number of species used in the creation of the gvectors.

Let us pack the gvectors we have generated in the previous step of the tutorial into tfr files:

```
python3 ../../panna/tfr_packer.py --config ./input_files/tfr_sample.ini
```

This will create our input files for training (or evaluation) in the specified folder (`tfr` for this tutorial) as a certain number of `.tfrecord` files, with a progressive identification number.

####REFERENCES

    [1] J. Behler and M. Parrinello, Generalized Neural-Network 
    Representation  of  High-Dimensional  Potential-Energy
    Surfaces, Phys. Rev. Lett. 98, 146401 (2007)
    [2] Justin S. Smith, Olexandr Isayev, Adrian E. Roitberg. 
    ANI-1: An extensible neural network potential with DFT accuracy 
    at force field computational cost. Chemical Science,(2017), DOI: 10.1039/C6SC05720A
